# 빈도수를 통해서 wordcloud 표현

from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt

data = {'국민':26, '대통령':33, '대한민국':9, '좋은나라':50} # 변수를 dictionary로 만들고 cloud하면 가능하다.

wordcloud = WordCloud(font_path="c:\windows\Fonts\malgunbd.ttf",stopwords=STOPWORDS,background_color='White',width=1000,height=800).generate_from_frequencies(data)
plt.figure(figsize=(10,10))
plt.imshow(wordcloud)
plt.axis('off')
plt.show()

# 긍정, 부정 언어

from nltk.tokenize import word_tokenize
import nltk
nltk.download('punkt')
from konlpy.tag import Twitter
pos_tagger=Twitter()

# 문장에 목표변수를 넣고 실행, 많이 만들어 줘야한다.
train=[('홍길동은 좋아','긍정'),('강아지는 무지좋아','긍정'),('수업이 재미없어','부정'),('홍길동은 이쁜 강아지야','긍정'),('난 수업을 마치고 홍길동이랑 놀거야','긍정'),('오늘 하루는 너무 짜증스러운 날이야','부정'),('날이 맑아서 좋아','긍정'),('오늘 지하철에 사람이 너무 많아서 짜증이 난다','부정'),('지하철에서 질서는 너무 없어 짜증이 난다','부정'),('비가 오니 짜증난다','부정'),('친구가 짜증낸다','부정'),('하늘이 맑아서 행복하다','긍정'),('공기가 맑아서 좋다','긍정'),('밝게 인사해주니 행복하다','긍정')] 

allword = set(word for sentence in train for word in word_tokenize(sentence[0]))
allword # tarin에 있는 단어들만 가져온다.

t = [({word : (word in word_tokenize(x[0])) for word in allword},x[1]) for x in train ] #★★★ 해석

# NaiveBayes를 통한 언어 분류 방법

classifier = nltk.NaiveBayesClassifier.train(t)
classifier.show_most_informative_features()

# 너무가 없을 경우 긍정의 확률이 높은지 부정의 확률이 높은지 파악

너무 = False              긍정 : 부정     =      1.9 : 1.0 
맑아서 = False            부정 : 긍정     =      1.5 : 1.0
짜증이 = False            긍정 : 부정     =      1.5 : 1.0
오늘 = False              긍정 : 부정     =      1.5 : 1.0
난다 = False              긍정 : 부정     =      1.5 : 1.0
홍길동은 = False          부정 : 긍정     =      1.3 : 1.0
행복하다 = False          부정 : 긍정     =      1.3 : 1.0
좋아 = False              부정 : 긍정     =      1.3 : 1.0
친구가 = False            긍정 : 부정     =      1.2 : 1.0
날이야 = False            긍정 : 부정     =      1.2 : 1.0

test = '난 수업을 마치면 홍길동이랑 놀거야'
test_f = {word : word in (word_tokenize(test)) for word in allword}

# 기존에 있는 classifier을 통해 비교

classifier.classify(test_f)

# 부정단어를 써서 부정 나오게하기
test = '오늘 왠지 짜증난다'
test_f = {word : word in (word_tokenize(test)) for word in allword}

classifier.classify(test_f)

# 개선할 방법: 1. 형태소 분석을 통한 방법

def tokenize(doc):
    return ['/'.join(t) for t in pos_tagger.pos(doc,norm=True,stem=True)]

train_doc = [(tokenize(row[0]),row[1]) for row in train]
train_doc

tokens = [t for d in train_doc for t in d[0]]
tokens

# 중복 제거 

def term_exists(doc):
    return {word : (word in set(doc)) for word in tokens}
    
train_x = [(term_exists(d),c) for d,c in train_doc] # 중복 제거를 통한 값 train 실행
train_x

classifier = nltk.NaiveBayesClassifier.train(train_x)
classifier.show_most_informative_features()

test = [("홍길동이랑 놀거야")]
test_doc = tokenize(test[0]) # list 형으로 해야 tokenize가 실행이 된다.
test_f = {word : (word in tokens) for word in test_doc}
classifier.classify(test_f)

test = [("오늘 왠일이니 짜증난다")]
test_doc = tokenize(test[0])
test_f = {word : (word in tokens) for word in test_doc}
classifier.classify(test_f)

# 의사결정트리 - 의사결정규칙(Decision rule)을 나무구조(Tree)로 도표화하여 분류(classfication)와 예측(prediction)을 수행하는 방법
# 활용분야 
    - 은행분야 : 도산업체 분류(예측) 과거의 데이터로 부터 도산기업과 도산하지않은 기업을 찾아내는 방법 
    - 카드발급대상 : 신용불량자 분류(예측)
    - 통신 : 이탈고객(해지자, 번호이동) 분류, 새로운 서비스 대상 고객선정
    - 쇼핑 : Direct mailing 대상 고객 선정
    
# 결정트리 장점
    - 지도학습(분류,예측)의 데이터 마이닝 기법
    - 적용결과에 의해 if -then 으로 표현하는 규칙이 생성
    - 규칙의 이행이 쉽고 SQL로도 할수 있다.
    - 많은 분야에서는 결정을 내리게 된데 대한 이유를 설명하는 능력이 중요하다.(해석력)

# 분류나무(classificaton tree)
    - 목표변수 : 범주형 (도산 vs 정상, 좋음 vs 나쁨)
    - 분류 알고리즘 
            CART : 지니지수 (Gini index)
            C5.0 : 엔트로피지수 (Entropy index)
            CHAID : 카이제곱통계량 (Chi-Square statistic)

# 교차분석 
    - 교차분석은 범주형(명목척도, 서열척도)으로 구성된 자료들간의 연관관계를 확인하기 위해 교차료를 만들어 관계를 확인하는 방법
    - 변수들의 빈도를 확인하고 그 빈도를 이용하여 상호 연관성을 판단한다. (빈도를 이용하는 이유는 명목척도 이기때문이다.)
    - 이때 검정통계량으로 카이제곱(χ²)통계량을 이용하기 때문에 카이제곱검정이라고 한다.
    - 카이제곱(Chi-Square)검정을 하기 위해서 교차표, 관측빈도, 기대빈도, 카이제곱통계량, 카이제곱분포의 자유도가 있어야한다.

# 교차표
    - 2개의 조사요인에 대한 자료값을 각각 행과 열로 배열하여 교차되는 항목에 대한 빈도를 나타낸 표를 교차료라한다.
    - 교차표의 행과 열에 범주형(명목척도)변수를 구분하여 넣으면 서로 연관성이 있는 빈도를 확인 할 수 있다.
    
예) 지역 1과 지역 2로 구분하여 최신 스마트폰의 구매 의사에 대한 각각의 행과 열에 해당하는 빈도를 표시한 교차표

                    구매의사
                    있음     없음    행의합
------------------------------------------
지역 1            154         52      206
     2            7           112     119  
-------------------------------------------
열의합            161         164      325

관측빈도(observed frequency)
- 교차표를 작성할 때에는 직접 수집한 데이터를 기준으로 빈도를 입력해야 하는데 이처럼 실제로 수집된 데이터의 빈도를 관측빈도라고 한다.

기대빈도(expected frequency)
- 기대빈도는 전체빈도 n에 대하여 행과열의 합을 기준으로 보았을 때 각 교차되는 셀에 몇번의 빈도가 확인될 수 있을지를 예상하는 기대값이다.
            
            행의 합 * 열의 합
기대빈도  = -------------------
                  관측수

                    구매의사
                    있음     없음    행의합
------------------------------------------
지역 1            154         52      206
기대빈도           102       104
1 - 기대빈도        52        -52
     2             7           112     119
기대빈도           59         60
2 - 기대빈도       -52         52
-------------------------------------------
열의합            161         164      325



기대  지역 1 구매 있음 (206*161)/325     
      지역 1 구매 없음 (206*164)/325
      지역 2 구매 있음 (161*119)/325
      지역 2 구매 없음 (164*119)/325

카이제곱 통계량 (카이제곱검정)
- 카이제곱통계량이란 관측빈도와 기대빈도 사이의 유의한 차이가 있는지를 확인하는 통계량을 의미한다.

                (관측빈도-기대빈도)²
카이제곱(χ²) = Σ --------------
                    기대빈도

(52**2)/102+(52**2)/104+(52**2)/59+(52**2)/60 = 143.4

카이제곱분포에서의 자유도
- 카이제곱검정을 실시하는 경우에는 P값을 이용할 수 있으며, 카이제곱 분포의 유의수준과 자유도에 따라 결과를 판단한다.
# p값 : 귀무가설을 기각할 수 있는 값 

df(degree of freedom) 자유도 = k-1 (k는 범주형의 변수의 수)
- 교차표에서 구성된 범주에 대한 자유도를 계산하는 방법은 교차표의 (행의 수-1) * (열의 수 -1)

df = (2-1) * (2-1) =1

# 독립성 검정 (independence test)
1. 가설수립 : 각 범주가 서로 독립적인지 아닌지에 대한 검정이므로 귀무가설은 독립인 것이다.

Ho(Null Hypothesis) 귀무가설, 영가설
- 귀무가설은 일반적으로 믿어온 사실을 가설로 설정한다.
- 귀무가설은 당연한 사실이나 연구할 의미가 없는 가설로 설정한다.

H1 (Anti Hypothesis) 대립가설, 연구가설
- 공공연하게 사실로 받아들여진 현상에 대립되는 가설로 연구를 통한 대립가설의 조사는 의미가 있다.

Ho : 지역과 구매의사는 독립이다. (지역과 구매의사는 아무의미가 없다)
H1 : 지역과 구매의사는 독립이 아니다. (지역과 구매의사는 의미가 있다.)

2. 교차표, 교차빈도
3. 기대빈도
4. 카이제곱통계량
5. 자유도 
6. 임계치 : 카이제곱 분포표에서 α=0.01 (99%) 유의수준
            자유도 (df=1) 임계치는 6.63 (카이제곱분포표 확인) 이므로
            143.3 보다 작다.
7. 귀무가설을 기각, 대립가설을 채택한다.

import csv
import pandas as pd
import numpy as np

tree=pd.read_csv('c:/data/tree.csv')

# 1. 습도, 테니스 유무

x = np.array(tree['습도'])
y = np.array(tree['테니스유무'])
z = pd.crosstab(a,b, rownames=['습도'], colnames=['테니스유무'])

4-5*7/14 = 1.5     
3-9*7/14 = -1.5
1-5*7/14 = -1.5
6-9*7/14 = 1.5

k=(2.25/2.5)*2+(2.25/4.5)*2=2.8

자유도 (2-1)*(2-1) : 1

유의수준 95% 경우

Ho : 습도는 테니스 경기에 영향을 주지않는다
H1 : 습도는 테니스 경기에 영향을 준다.

# 2. 날씨, 테니스 유무

x1=np.array(tree['날씨'])
z1=pd.crosstab(x1,y, rownames=['날씨'], colnames=['테니스유무'])

z1['열의합']=[sum(z1.iloc[0]),sum(z1.iloc[1]),sum(z1.iloc[2])]
z1=z1.drop('행의합')
a=sum(z1['아니요'])
b=sum(z1['예'])
c=sum(z1['열의합'])
z1.at['행의합','아니요']=a
z1.at['행의합','예']=b
z1.at['행의합','열의합']=c

z1.ix['행의합'][-1]


            









    
            
            
            
            
            
            
    
    
    



