# c:/centos 에 centos.iso를 저장

# virtual 설치후 파일 - 환경설정 - 입력 - 가상머신 - 호스트키조합 : 윈도우즈와 linux를 왔다갔다 하기위해 해야함
# 가상머신 - 네트워크 - 새 NAT추가 - 편집으로 확인 - 호스트 전용네트워크 - 편집누르고 확인 - DHPC의 최저/최고 주소 끼리 setup 하기위해 확인해야함 101~254
# 새로만들기 - 서버이름 짓기 (아무이름이나 가능) - Red hat 버젼으로 반드시 해야함 - 다음 - 메모리크기 (8기가 짜리지만 2048로 지정) - 다음 - 지금하드디스크 만들기
# - 다음 - VDI - 다음 - 동적할당 - 다음 - 파일위치 용량 (30G, 8G너무적음) 용량은 자기마음대로 해도되지만, 할당될수 있는 크기까지만 가능하다. - 만들기 
# 만든후 설정 - 일반 - 고급 - 클립보드,드래그 모두 양방향 (파일을 자유롭게 옮기기 위해) - 시스템 - 플로피디스크 제거 - 저장소 - 비어있음클릭 - 광학드라이브 옆 배너클릭
# c:/centos 로 들어가 iso 열기  - 오디오 해제 - 네트워크 - 어댑터 1에서 고급눌러서 케이블연결까지 되어있는지 확인 - 어댑터 2가서 사용하기 누르고 -
# 호스트전용으로가고 - 무작위모드를 모두허용으로 바꾼다 .- 케이블연결 체크 - 공유폴더 - 폴더 클릭하고 윈도우에서 공유폴더를 만들어 리눅스에서 편하게 만드려고 폴더 설정
# 자동마운트만 체크후 확인 - 시작을 누른다.
# test this 선택 후 실행 - 한국어 선택 후 - 키보드 영어(미국) 추가후 맨위로 - 소프트웨어 선택에서 GNOME 선택후 개발용도구 선택 - 시스템 설정대상 누르고 완료 누르면됨
# kdump 비활성화 - 네트워크 들어가서 NAT과 HOST 확인 후 둘다 켬으로 바꾼다. - 밑에 호스트이름에 영어로만 가능하고 적용시킨다. - 설치시작
# root암호 설정한다 - 사용자생성 

오른쪽 버튼 - 터미널 

id  -  아이디랑 값이 나옴
ifconfig - 이더넷 1, 2 정보가 나옴 (NAT,Host )
# ★★ centos로 들어온 경우 root로 들어온다
 cd - change directory
 
cd /etc/sysconfig/network-scripts
pwd - 현재 디렉토리
ls - 디렉토리에 있는 파일정보 확인
ll - 조금더 디테일한 파일정보 확인
cat ifcfg-enp0s3 # enp0s3에 있는 값
# tab 2번 누르면 명령어와 비슷한값 나옴

# 윈도우에서 종료하면 저장한상태 그대로 나오는 것이 가능하다.
cp ifcfg-enp0s3 test.txt # cp 원본 새로운파일 txt

유저이름@서버이름 
ls test.txt # 파일확인

# ★★ vi편집기
vi test.txt # 파일 들어가기 , vi 메모장

vi 
$ 그행의 끝값 
^ home키와 같다.
gg 제일 앞으로 온다.
G 제일 뒤로간다.
5G - 숫자G 숫자위치값으로이동한다.

esc :q! # 창닫기
esc :5 # 5번째 줄 이동
i - insert
del - 지우기 
a - 커서가 있는값 다음값으로 가서 진행
I - 커서가 맨앞으로가서 입력값이 켜짐
A - 커서가 제일 뒤로간다.
O - 문단사이에 입력 (현재커서의 위에 값을 적을 수 있다.)
o - 다음줄에 입력을 할 수 있다.
dd - 커서 한줄이 지워진다.
 x - 소문자 한개씩 지우다
 r - 커서에 있는값 수정
cw - 단어가 지워진다.
:wq - 입력한 값 저장후 나가기
X - 줄을 지운다
2dd - 숫자만큼 줄을 지운다.
yy - 복사 
p  - 붙어넣기
P(대문자) - 문장 전체 붙어넣기
/단어 - 단어가 있는 곳으로 커서를 옮겨준다.

# ifcfg-enp0s3- 인터넷이 안되면 boot값을 yes로 바꾼다.
vi ifcfg-enp0s8 # host 내용정보
dhcp값을 바꿔야한다.
none으로 바꾼다.
cw - 단어삭제
onboot 값도 yes로 바꾼다.
NETMASK
 맨밑에
# NETMASK 255.255.255.0 통로만들기
# IPDDR=192.168.56.101

service network restart - network 저장된거 다시 적용
ifconfig 적용 확인

# 윈도우 

장치 - 게스트확장 cd를 눌러서 확인을 누른다.
# reboot를 하면 ctrl+alt 상관없이 재부팅이 가능하다.
공유폴더가 설정된다.  그리고 리눅스에서 복사 한것을 바로 붙어넣기 하는것이 가능해진다.
창 키우기도 가능하다. 


바탕화면 CD를 없애고 싶다면 꺼내기하면 지워진다.

[root@centos ~]# cat /etc/hosts - 안에있는 내용 미리보기
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6

# 서버의 주소 mapping 시키기
vi /etc/hosts

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.56.101 centos # 이값 입력 이 맵핑을 해주는 것이다.

reboot하면 적용이 된다.
init 0 종료를한다.

whoami : 자기 이름 계정 나옴
su - centos : centos로 이동한다
su - : 루트로 돌아온다
hostname : host주소이름이 나온다.

# 서버이름 바꾸기 - reboot을 해야 적용이 된다.
hostnamectl set-hostname 서버이름
hostnamectl set-hostname dataserver

NAT - 밖으로 나가기 위한 망
host - 리눅스끼리 or 리눅스 안에서의 네트워크 망

cd /etc
ls
cd # 이전의 값
pwd

ifconfig - 아이피 확인
# enp0s3: NAT, 어댑터1, 주소를 dinamic하게 받음
# enp0s8: host, 어댑터2, 수동으로 고정하여서 값을 받는 것이 좋다.
# 설정방법 : DHCP의 최저주소, 최고주소 값의 사이에서 지정을 한다.

etc/sysconfig/network-scripts
ls

# ifcfg-enp0s8 에서
BOOTPROTO=none
ONBOOT=yes
NETMASK=255.255.255.0 #고정
IPDDR=192.168.56.101 # 아이피는 다른값

vi /etc/hosts
centos에서
dataserver로 이름을 바꾼다

장치에서 게스트확장을 해야 공유폴더를 활성화 하는것이 가능하다.

# ls -l,ls -a,ls 비교
ls : 현재디렉토리 파일 목록
ls -a : 현재 디렉토리 숨김파일도 같이 보는 것이 가능하다. 
ls -l : 현재 디렉토리의 목록을 자세히보여주고, 권한을 보여준다.

#drwxr : 권한을 의미한다.  (read, write, excute) (-은 불가능을 의미)
drwxr-xr-x. 2 root root    6 11월 19 17:00 공개
drwxr-xr-x. 2 root root    6 11월 19 17:00 다운로드
drwxr-xr-x. 2 root root    6 11월 19 17:00 문서
drwxr-xr-x. 2 root root    6 11월 19 17:00 바탕화면
drwxr-xr-x. 2 root root    6 11월 19 17:00 비디오
drwxr-xr-x. 2 root root    6 11월 19 17:00 사진
drwxr-xr-x. 2 root root    6 11월 19 17:00 서식
drwxr-xr-x. 2 root root    6 11월 19 17:00 음악
권한      소유자이름 그룹

rwx(소유자)-xr(그룹)-x(그 외의 사용자) 가 사용할 수 있는 범위를 의미한다.

# cd ~ : 홈디렉토리로 이동된다.
cd ~centos

# touch : 파일생성 , 크기가 0인 파일을 생성한다 , 이미 파일이 존재한다면 파일의 최종시간이 바뀐다.
touch test.txt
ls -l test.txt

# rm : 파일삭제, 물어볼 때 y를 누르면 삭제, 파일을 삭제하면 다시 불러올 수 없다 ★
rm test.txt
rm -i test.txt # 삭제
rm -f test.txt # 묻지 않고 바로 삭제

# mkdir - 디렉토리 생성
mkdir data
mkdir /home/data
 
#cd .. (cd 한칸띄우고) : 가장 최상위 층으로 감
cd /home 
mkdir -p /home/data # -p : directory에 직접가지 않고 원하는 곳에 디렉토리 데이터 생성

# rmdir - 디렉토리 삭제, 디렉토리 삭제를 할 때는 디렉토리가 비워져 있을 때만 가능하다.
rmdir data 

# 빈디렉토리에 상관없이 삭제하고 싶다면 rm을 사용한다
rm -r data1
rm -rf data1 # 묻지않고 바로 삭제

# 하둡 설치하기 
- 방화벽 해제하기 : 해제해야 가능 
- iptables -L : 방화벽 확인
- iptables -F : 방화벽 삭제
- java -version : java버전 확인, OpenJDK는 잘되지 않는다 그래서 oracle jdk를 사용한다.
- cd /media/sf_centos/ : 공유폴더 입장
- ls jdk* : jdk이름이 있는 값 생성
- tar : 리눅스용 압축파일
- cp jdk-7u80-linux-x64.tar.gz /usr : usr에 복사 
- cd /usr : usr 디렉토리 확인
- tar xvfz jdk-7u80-linux-x64.tar.gz : 압축해제
- cd jdk1.7.0_80/ : 압축을 푼 후 들어간다.
pwd 를 하면 /usr/jdk1.7.0_80 <이값이 javahome이다>

# xvfz
x - 묶음 해제 , v - 화면에 표시 , f - 파일이름 지정, z - gunzip을 사용

★★ JAVAHOME 환경설정
 vi /etc/profile
맨밑으로 간 후에 아래와 같이 입력한다.

export JAVA_HOME=/usr/jdk1.7.0_80 # 자바홈 값입력
export PATH=$PATH:$JAVA_HOME/bin
export CLASS_PATH="."
- source : 값 적용
source /etc/profile # 세이브한 값을 적용 시킨다

/usr/bin/java
update-alternatives --install "/usr/bin/java" "java" "/usr/jdk1.7.0_80/bin/java" 1
update-alternatives --config java # 등록되어잇는 JDK 모두나옴 , jre 한 것을 선택

# 프로토콜 버퍼 설치 
- 구글에서 만든 오픈소스 직렬화 라이브러리
- 이기종 서버간의 데이터 통신은 서로 다른 종류의 언어로 개발 된 시스템간의 데이터를 전달하는 방식 text format, binary format 데이터를 이용한다.
- text format 방식은 데이터를 이해하기 쉽고, 각 언어별로 파서를 제공한다. 단점은 데이터 자체가 크면 파서의 성능은 떨어진다.
- binary format 방식은 데이터 크기가 작다. 성능이 좋다. 단점은 바이너리 코드를 만들고 해독해야하는 모듈을 만들어야하는 부담이 있다.
- 하둡 2에서 데몬간의 데이터 통신을 위해 protocol buffer를 사용한다.

★★ 설치
- cd /media/sf_sentos/
- ls protobuf*
- cp protobuf-2.5.0.tar.gz /usr/local
- cd /usr/local 간후 ls : 값 확인
- tar xvfz protobuf-2.5.0.tar.gz : 압축풀기
- cd protobuf-2.5.0
- ./configure : 환경설정
- make : 소스값 저장
- make install : 설치완료
- protoc --version : 설치 확인

# hadoop은 유저 생성을해서 따로 설치를 해야한다.

#### 유저관리 #####

cat /etc/passwd : 현재 유저들을 볼 수 있다.
head -1 /etc/passwd : 가장 위값
tail -2 /etc/passwd : 가장 밑에 2개의 값
root:x:0:0:root:/root:/bin/bash # 사용자이름:암호:사용자ID:사용자가 소속된 그룹ID:전체이름:홈디렉토리/기본쉘

useradd(adduser) : 유저 생성 명령어
- ex) useradd user10
- tail -1 /etc/passwd : 만들어진거 확인

userdel 사용자 삭제
- ex) userdel -r user10
 
# 그룹생성
groupadd hadoop
cat /etc/group - 그룹 생성 확인

# 그룹삭제
groupdel hadoop

# 유저생성
useradd -g hadoop -G vboxsf -m hadoop : 생성한 그룹을 사용하는 유저를 설정함
	   1차그룹  -G 2차그룹  -m 유저이름 , -m은 기본 디렉토리 생성을 의미
2차그룹이 생기는 것은 장치 - 게스트확장 CD 이미지삽입을 하면 값이 생기고 공유폴더를 사용할 수 있게 만든다.
즉, 홈 디렉토리를 생성한다.

#  비밀번호 설정
passwd hadoop
- 8글자 이상이지만 비밀번호는 hadoop 
# 사용자 바꾸기 - hadoop 선택해서 접속

- cd /media/sf_centos/ # 공유폴더 접속

####### 하둡 설치 ##########
hadoop 로 접속
cp hadoop-2.7.2.tar.gz /home/hadoop
cd
ls
tar xvfz hadoop-2.7.2.tar.gz : 압축풀기
ls
vi .bashrc : 편집기 열기

★ 편집 맨 밑에 값 저장
export JAVA_HOME=/usr/jdk1.7.0_80 
export HADOOP_HOME=/home/hadoop/hadoop-2.7.2
export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

source .bashrc
java -version

# SSH설정 
공개키는 사용자 계정의 홈디렉토리에 있는 .ssh폴더에 생성된다.
rm -rf .ssh # 지우기
ssh-keygen # 키생성
enter - enter - enter 하게되면 공개키 생성

ssh-copy-id -i /home/hadoop/.ssh/id_rsa.pub hadoop@192.168.56.102 # 아까 enp0s8번에 있는 값으로 지정하면된다.
continue connecting - yes

hadoop password 물어보면 hadoop을 누른다.
cd /home/hadoop/hadoop-2.7.2/etc/hadoop

##vi hadoop-env.sh # 하둡 편집기 접속

수정해야 할 값 : export JAVA_HOME=${JAVA_HOME}
수정하기 : export JAVA_HOME=/usr/jdk1.7.0_80

수정해야 할 값 : export HADOOP_PID_DIR=${HADOOP_PID_DIR}
수정하기 : export HADOOP_PID_DIR=/home/hadoop/hadoop-2.7.2/pids

# vi masters - enp0s8에 해당하는 값 넣는다.
192.168.56.102

# vi slaves
localhost 지우고 enp0s8에 해당하는 값 넣는다.
192.168.56.102

# vi core-site.xml



#### 선생님 코드 #####
'''
cd /home/hadoop/hadoop-2.7.2/etc/hadoop

[hadoop@dataserver hadoop]$ vi hadoop-env.sh
export JAVA_HOME=/usr/jdk1.7.0_80
export HADOOP_PID_DIR=/home/hadoop/hadoop-2.7.2/pids

[hadoop@dataserver hadoop]$ vi masters
192.168.56.101
[hadoop@dataserver hadoop]$ vi slaves
192.168.56.101

[hadoop@dataserver hadoop]$ vi core-site.xml 

<configuration>
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://dataserver:9010</value> 
 </property>
</configuration>


[hadoop@dataserver hadoop]$ vi hdfs-site.xml 

<configuration>
 <property>
  <name>dfs.replication</name>
  <value>1</value>
 </property>
 <property>
  <name>dfs.namenode.name.dir</name>
  <value>/home/hadoop/data/dfs/namenode</value>
 </property>
 <property>
  <name>dfs.namenode.checkpoint.dir</name>
  <value>/home/hadoop/data/dfs/namesecondary</value>
 </property>
 <property>
  <name>dfs.datanode.data.dir</name>
  <value>/home/hadoop/data/dfs/datanode</value>
 </property>
 <property>
  <name>dfs.http.address</name>
  <value>dataserver:50070</value>
 </property>
 <property>
  <name>dfs.secondary.http.address</name>
  <value>dataserver:50090</value>
 </property>
</configuration>


[hadoop@dataserver hadoop]$ cp mapred-site.xml.template mapred-site.xml
[hadoop@dataserver hadoop]$ vi mapred-site.xml

<configuration>
 <property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
 </property>
</configuration>

[hadoop@dataserver hadoop]$ vi yarn-site.xml 

<configuration>
 <property>
  <name>yarn.nodemanager.aux-services</name>
  <value>mapreduce_shuffle</value>
 </property>
 <property>
  <name>yarn.nodemanager.aux-services.mapreduce_suffle.class</name>
  <value>org.apache.hadoop.mapred.ShuffleHandler</value>
 </property>
 <property>
  <name>yarn.nodemanager.local-dirs</name>
  <value>/home/hadoop/data/yarn/nm-local-dir</value>
 </property>
 <property>
  <name>yarn.resourcemanager.fs.state-store.uri</name>
  <value>/home/hadoop/data/yarn/system/rmstore</value>
 </property>
 <property>
  <name>yarn.resourcemanager.hostname</name>
  <value>dataserver</value>
 </property>
 <property>
  <name>yarn.web-proxy.address</name>
  <value>0.0.0.0:8089</value>
 </property>
</configuration>
'''
#<!-- Site specific YARN configuration properties --i>

cd
hdfs namenode -format

/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at dataserver/192.168.56.101 # 나오면 완료
************************************************************/

#하둡데몬시작
start-dfs.sh
start-yarn.sh
mr-jobhistory-daemon.sh start historyserver
yarn-daemon.sh start proxyserver    

jps

#하둡데몬종료
stop-yarn.sh
stop-dfs.sh
mr-jobhistory-daemon.sh stop historyserver

mr-jobhistory-daemon.sh stop historyserver

BigData - 서버 한대로 처리할 수 없는 규모의 데이터 (2012 john rauser, 아마존 수석 엔지니어)
          - 기존 소프트웨러로 처리 할 수 없는 규모의 데이터
          - scale up : 하드웨어 증설
          - scale out : 비슷한 사양의 서버로 분산처리

하둡 분산형 파일시스템 (HDFS(Hadoop Distributed File System))

하둡은 대용량 데이터를 분산처리 할 수 있는 자바기반의 오픈소스 프레임워크이다.

구글이 쌓여지는 수많은 빅데이터 (웹페이지,데이터..) 들을 구글에서도 처음에는 RDBMS(ORACLE)에 입력하고 데이터를 저장하고 처리하려는 시도를 
했으나 너무 데이터가 많아서 실패를 하고 자체적으로 빅데이터를 처리할 기술을 개발하고 대외적으로 논물을 발표했다.

이 논문을 더그커팅이 읽고 자바로 구현을 했다.

RDMS ----------------------------------------------------- hadoop
(ORACLE) 
실시간 데이터 처리			      배치처리(READ) / 조회성 / 무료 / 분산처리 가능
# 데이터의 품질 좋다. (제약조건등 여러가지)

분산처리 : 여러대의 노드를 묶어서 마치 하나의 서버처럼 보이게 하고 여러 노드의 자원을 이용해서 데이터를 처리하기 때문에 처리하는 속도가 빠르다.

실사례 : 2008년 뉴욕타임즈의 130년 분량의 신문기사 1100만 페이지를 하둡을 이용해서 하루만에 PDF로 변환했고 비용은 200만원 밖에 안들었다.
하둡이 아닌 일반 서류로 처리했다면 14년이 걸린다.

[hadoop@dataserver ~]$ jps
24141 Jps
23838 NodeManager
21487 SecondaryNameNode
23678 ResourceManager
24110 WebAppProxyServer
24025 JobHistoryServer
16766 DataNode
16544 NameNode # 하둡이름, 집어넣어야 할 데이터를 지정

[hadoop@dataserver ~]$ hdfs dfs -ls /
Found 1 items
drwxrwx---   - hadoop supergroup          0 2018-11-21 11:53 /tmp
[hadoop@dataserver ~]$ hdfs dfs -mkdir /user # 디렉토리 생성 : hdfs dfs -명령어 /디렉토리
[hadoop@dataserver ~]$ hdfs dfs -mkdir /user/hadoop # user 안에 hadoop 디렉토리 생성
[hadoop@dataserver ~]$ hdfs dfs -ls -R / # 안에있는 디렉토리 정보까지 나온다.

hdfs dfs -mkdir /user/hadoop/conf
hdfs dfs -ls -R /


# put : os 에 있는 파일을 하둡파일 시스템에 올리는 명령어 
hdfs dfs -put  /home/hadoop/hadoop-2.7.2/etc/hadoop/hadoop-env.sh conf/
hdfs dfs -ls conf/ : 파일 확인
hdfs dfs -cat conf/hadoop-env.sh

cd /home/hadoop/hadoop-2.7.2/share/hadoop/mapreduce # map: 흩어버리다 , reduce 줄이다 합치다.
ls
[hadoop@dataserver mapreduce]$ ls
hadoop-mapreduce-client-app-2.7.2.jar
hadoop-mapreduce-client-common-2.7.2.jar
hadoop-mapreduce-client-core-2.7.2.jar
hadoop-mapreduce-client-hs-2.7.2.jar
hadoop-mapreduce-client-hs-plugins-2.7.2.jar
hadoop-mapreduce-client-jobclient-2.7.2-tests.jar
hadoop-mapreduce-client-jobclient-2.7.2.jar
hadoop-mapreduce-client-shuffle-2.7.2.jar
hadoop-mapreduce-examples-2.7.2.jar # 워드 카운트를 사용하는 프로그램

# hadoop-mapreduce-examples-2.7.2.jar를 통해 워드카운트하여 추출
yarn jar hadoop-mapreduce-examples-2.7.2.jar wordcount conf output

[hadoop@dataserver mapreduce]$ yarn jar hadoop-mapreduce-examples-2.7.2.jar wordcount conf output
18/11/21 14:54:14 INFO client.RMProxy: Connecting to ResourceManager at dataserver/10.0.2.15:8032
18/11/21 14:54:21 INFO input.FileInputFormat: Total input paths to process : 1
18/11/21 14:54:21 INFO mapreduce.JobSubmitter: number of splits:1
18/11/21 14:54:24 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1542768788819_0001
18/11/21 14:54:28 INFO impl.YarnClientImpl: Submitted application application_1542768788819_0001
18/11/21 14:54:29 INFO mapreduce.Job: The url to track the job: http://0.0.0.0:8089/proxy/application_1542768788819_0001/
18/11/21 14:54:29 INFO mapreduce.Job: Running job: job_1542768788819_0001
18/11/21 14:56:00 INFO mapreduce.Job: Job job_1542768788819_0001 running in uber mode : false
18/11/21 14:56:00 INFO mapreduce.Job:  map 0% reduce 0%
18/11/21 14:57:13 INFO mapreduce.Job:  map 100% reduce 0%
18/11/21 14:58:23 INFO mapreduce.Job:  map 100% reduce 100%
18/11/21 14:58:29 INFO mapreduce.Job: Job job_1542768788819_0001 completed successfully
18/11/21 14:58:30 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=4532
		FILE: Number of bytes written=244587
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=4356
		HDFS: Number of bytes written=3459
		HDFS: Number of read operations=6
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=66444
		Total time spent by all reduces in occupied slots (ms)=69303
		Total time spent by all map tasks (ms)=66444
		Total time spent by all reduce tasks (ms)=69303
		Total vcore-milliseconds taken by all map tasks=66444
		Total vcore-milliseconds taken by all reduce tasks=69303
		Total megabyte-milliseconds taken by all map tasks=68038656
		Total megabyte-milliseconds taken by all reduce tasks=70966272
	Map-Reduce Framework
		Map input records=98
		Map output records=519
		Map output bytes=6253
		Map output materialized bytes=4532
		Input split bytes=118
		Combine input records=519
		Combine output records=268
		Reduce input groups=268
		Reduce shuffle bytes=4532
		Reduce input records=268
		Reduce output records=268
		Spilled Records=536
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1067
		CPU time spent (ms)=9170
		Physical memory (bytes) snapshot=300761088
		Virtual memory (bytes) snapshot=1757741056
		Total committed heap usage (bytes)=168497152
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4238
	File Output Format Counters 
		Bytes Written=3459

[hadoop@dataserver mapreduce]$ hdfs dfs -ls output
Found 2 items
-rw-r--r--   1 hadoop supergroup          0 2018-11-21 14:58 output/_SUCCESS
-rw-r--r--   1 hadoop supergroup       3459 2018-11-21 14:58 output/part-r-00000
[hadoop@dataserver mapreduce]$ 

하둡 데몬 종료
stop-yarn.sh
stop-dfs.sh
mr-jobhistory-daemon.sh stop history

# datanode가 뜨지않을경우 값을 지우고 해야한다.
rm -rf data
hdfs namenode -format

하둡시작
start-dfs.sh
start-yarn.s
mr-jobhistory-daemon.sh start history
yarn-daemon.sh start proxyserver
jps

다시 디렉토리 실행 후 
hdfs dfs -cat output/part-r-00000 | tail -10

# get : 하둡데이터 os로 내리기
hdfs dfs -get output/part-r-00000 /home/hadoop/wc_output
cat /home/hadoop/wc_output

hdfs dfs -put  /home/hadoop/hadoop-2.7.2/etc/hadoop/hadoop-env.sh conf/
cd /media/sf_sentos/















